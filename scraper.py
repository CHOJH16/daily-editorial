import requests
from bs4 import BeautifulSoup
import datetime
import os
import time

# --- ì„¤ì • ---
# ë„¤ì´ë²„ ë‰´ìŠ¤ ì‚¬ì„¤ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ (í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì ‘ê·¼ ê°€ëŠ¥)
target_url_base = "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=110&sid2=262"
headers = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
}

def send_msg(text):
    """í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ì „ì†¡ í•¨ìˆ˜"""
    token = os.environ.get('TELEGRAM_TOKEN')
    chat_id = os.environ.get('CHAT_ID')
    
    if not token or not chat_id:
        print("âŒ [ì˜¤ë¥˜] í…”ë ˆê·¸ë¨ ì„¤ì •(TOKEN, CHAT_ID)ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    url = f"https://api.telegram.org/bot{token}/sendMessage"
    try:
        data = {'chat_id': chat_id, 'text': text, 'disable_web_page_preview': True}
        requests.post(url, data=data)
    except Exception as e:
        print(f"âŒ [ì˜¤ë¥˜] í…”ë ˆê·¸ë¨ ì „ì†¡ ì‹¤íŒ¨: {e}")

def create_html(news_list):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    html = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ì˜¤ëŠ˜ì˜ ì‚¬ì„¤</title>
        <style>
            body {{ font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
            h1 {{ border-bottom: 2px solid #03c75a; padding-bottom: 10px; }}
            .card {{ border: 1px solid #ddd; padding: 15px; margin-bottom: 10px; border-radius: 5px; }}
            a {{ text-decoration: none; color: #333; font-weight: bold; font-size: 1.1em; }}
            .press {{ color: #03c75a; font-weight: bold; font-size: 0.9em; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ì‚¬ì„¤</h1>
        <p style="text-align:right">ì—…ë°ì´íŠ¸: {now} (ì´ {len(news_list)}ê°œ)</p>
    """
    for news in news_list:
        html += f"<div class='card'><span class='press'>{news['press']}</span><br><a href='{news['link']}' target='_blank'>{news['title']}</a></div>"
    html += "</body></html>"
    return html

# === ë©”ì¸ ì‹¤í–‰ ë¡œì§ ===
try:
    print("ğŸš€ ë¡œë´‡ ì‹œì‘!")
    # [ì§„ë‹¨ 1] ë¡œë´‡ì´ ê¹¨ì–´ë‚¬ìŒì„ ì•Œë¦¼
    send_msg("ğŸ¤– ë¡œë´‡ì´ ì‘ì—…ì„ ì‹œì‘í–ˆìŠµë‹ˆë‹¤.\n(ì´ ë©”ì‹œì§€ê°€ ì˜¤ë©´ ì„¤ì •ì€ ì •ìƒì…ë‹ˆë‹¤.)")

    news_data = []
    seen_links = set()

    # 1í˜ì´ì§€ ~ 3í˜ì´ì§€ íƒìƒ‰ (ì•½ 60ê°œ ê¸°ì‚¬)
    for page in range(1, 4):
        url = f"{target_url_base}&page={page}"
        print(f"ğŸ“¡ {page}í˜ì´ì§€ ì ‘ì† ì¤‘: {url}")
        
        res = requests.get(url, headers=headers)
        soup = BeautifulSoup(res.text, 'html.parser')

        # ë„¤ì´ë²„ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€ êµ¬ì¡°: ul.type06_headline ê³¼ ul.type06 ì•ˆì— ê¸°ì‚¬ê°€ ìˆìŒ
        # ì´ ë‘ ì¢…ë¥˜ì˜ ul ì•ˆì— ìˆëŠ” ëª¨ë“  lië¥¼ ì°¾ìŒ
        articles = soup.select('ul.type06_headline li') + soup.select('ul.type06 li')
        
        print(f"   -> {len(articles)}ê°œì˜ í•­ëª© ë°œê²¬")

        for item in articles:
            try:
                # dl íƒœê·¸ ì•ˆì— dt(ì œëª©/ì´ë¯¸ì§€), dd(ë‚´ìš©)ê°€ ìˆìŒ
                dt_tags = item.find_all('dt')
                a_tag = None
                
                # dtê°€ 2ê°œë©´(ì´ë¯¸ì§€ í¬í•¨), ë‘ ë²ˆì§¸ dtì— ì œëª©ì´ ìˆìŒ. 1ê°œë©´ ë°”ë¡œ ì œëª©.
                if len(dt_tags) == 2:
                    a_tag = dt_tags[1].find('a')
                elif len(dt_tags) == 1:
                    a_tag = dt_tags[0].find('a')
                
                if not a_tag: continue

                link = a_tag['href']
                title = a_tag.get_text(strip=True)
                
                if link in seen_links: continue

                # ì–¸ë¡ ì‚¬ ì´ë¦„ (span class="writing")
                press_span = item.find('span', class_='writing')
                press = press_span.get_text(strip=True) if press_span else "ì‚¬ì„¤"

                # ì œëª© ì •ë¦¬
                if title.startswith(press):
                    title = title[len(press):].lstrip('[] ')

                news_data.append({'title': title, 'link': link, 'press': press})
                seen_links.add(link)

            except Exception as e:
                print(f"   âš ï¸ í•­ëª© íŒŒì‹± ì¤‘ ì—ëŸ¬: {e}")
                continue
        
        time.sleep(0.5)

    print(f"âœ… ì´ {len(news_data)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ")

    if news_data:
        # íŒŒì¼ ì €ì¥
        with open("index.html", "w", encoding="utf-8") as f:
            f.write(create_html(news_data))
        
        # [ì§„ë‹¨ 2] ê²°ê³¼ ì „ì†¡
        msg = f"ğŸ“° ìˆ˜ì§‘ ì™„ë£Œ! ì´ {len(news_data)}ê°œ\n\n"
        # 5ê°œë§Œ ìƒ˜í”Œë¡œ ë³´ë‚´ê³  ë§í¬ ì•ˆë‚´
        for news in news_data[:5]:
            msg += f"[{news['press']}] {news['title']}\n"
        msg += f"\n...ì™¸ {len(news_data)-5}ê°œ\nğŸ‘‰ https://chojh16.github.io/daily-editorial/"
        
        send_msg(msg)
    else:
        send_msg("âŒ ê¸°ì‚¬ë¥¼ í•˜ë‚˜ë„ ëª» ì°¾ì•˜ìŠµë‹ˆë‹¤. (ë„¤ì´ë²„ êµ¬ì¡° ë³€ê²½ ì˜ì‹¬)")

except Exception as e:
    err_msg = f"ğŸ”¥ ì¹˜ëª…ì  ì—ëŸ¬ ë°œìƒ: {e}"
    print(err_msg)
    send_msg(err_msg)
    exit(1)
