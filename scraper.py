import requests
from bs4 import BeautifulSoup
import datetime
import os
import time

# --- ì„¤ì • ---
# ë„¤ì´ë²„ ë‰´ìŠ¤ ì‚¬ì„¤ ë¦¬ìŠ¤íŠ¸ í˜ì´ì§€
target_url_base = "https://news.naver.com/main/list.naver?mode=LS2D&mid=shm&sid1=110&sid2=262"
headers = {
    # ë´‡ ì°¨ë‹¨ì„ ë§‰ê¸° ìœ„í•œ ì¼ë°˜ ì‚¬ìš©ì ìœ„ì¥ í—¤ë”
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
    "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8"
}

def send_msg(text):
    token = os.environ.get('TELEGRAM_TOKEN')
    chat_id = os.environ.get('CHAT_ID')
    if not token or not chat_id: return
    try:
        url = f"https://api.telegram.org/bot{token}/sendMessage"
        data = {'chat_id': chat_id, 'text': text, 'disable_web_page_preview': True}
        requests.post(url, data=data)
    except: pass

def create_html(news_list):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    html = f"""
    <!DOCTYPE html>
    <html lang="ko">
    <head>
        <meta charset="UTF-8">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        <title>ì˜¤ëŠ˜ì˜ ì‚¬ì„¤</title>
        <style>
            body {{ font-family: sans-serif; max-width: 800px; margin: 0 auto; padding: 20px; }}
            h1 {{ border-bottom: 2px solid #03c75a; padding-bottom: 10px; }}
            .card {{ border: 1px solid #ddd; padding: 15px; margin-bottom: 10px; border-radius: 5px; }}
            a {{ text-decoration: none; color: #333; font-weight: bold; font-size: 1.1em; }}
            .press {{ color: #03c75a; font-weight: bold; font-size: 0.9em; }}
        </style>
    </head>
    <body>
        <h1>ğŸ“° ì˜¤ëŠ˜ì˜ ì£¼ìš” ì‚¬ì„¤</h1>
        <p style="text-align:right">ì—…ë°ì´íŠ¸: {now} (ì´ {len(news_list)}ê°œ)</p>
    """
    for news in news_list:
        html += f"<div class='card'><span class='press'>{news['press']}</span><br><a href='{news['link']}' target='_blank'>{news['title']}</a></div>"
    html += "</body></html>"
    return html

# === ë©”ì¸ ë¡œì§ ===
try:
    print("ğŸš€ ë¡œë´‡ ì‹œì‘")
    # ì‹œì‘ ë©”ì‹œì§€ëŠ” ìƒëµ (ë„ˆë¬´ ì‹œë„ëŸ¬ìš¸ ìˆ˜ ìˆì–´ì„œ)

    news_data = []
    seen_links = set()

    # 1í˜ì´ì§€ ~ 3í˜ì´ì§€ íƒìƒ‰
    for page in range(1, 4):
        url = f"{target_url_base}&page={page}"
        print(f"ì ‘ì†: {url}")
        
        res = requests.get(url, headers=headers)
        # HTML í…ìŠ¤íŠ¸ ì „ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        soup = BeautifulSoup(res.text, 'html.parser')

        # [í•µì‹¬ ë³€ê²½] íŠ¹ì • í´ë˜ìŠ¤(ul.type06)ë¥¼ ì°¾ì§€ ì•ŠìŠµë‹ˆë‹¤.
        # í˜ì´ì§€ ë‚´ì˜ 'ëª¨ë“ ' a íƒœê·¸ë¥¼ ë‹¤ ê°€ì ¸ì™€ì„œ ê²€ì‚¬í•©ë‹ˆë‹¤.
        all_links = soup.find_all('a')
        
        found_count = 0
        
        for a in all_links:
            try:
                link = a.get('href', '')
                title = a.get_text(strip=True)
                
                # 1. ë§í¬ê°€ ì—†ê±°ë‚˜ ì œëª©ì´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
                if not link or not title: continue
                
                # 2. ë§í¬ ì£¼ì†Œì— '/article/' (ê¸°ì‚¬ íŒ¨í„´)ì´ ì—†ìœ¼ë©´ íŒ¨ìŠ¤
                if '/article/' not in link: continue
                
                # 3. ì´ë¯¸ ì €ì¥í•œ ë§í¬ë©´ íŒ¨ìŠ¤
                if link in seen_links: continue
                
                # 4. ì–¸ë¡ ì‚¬ ì´ë¦„ ì°¾ê¸° (ì•½ê°„ì˜ ì¶”ì¸¡ ë¡œì§)
                # a íƒœê·¸ ê·¼ì²˜ì˜ ìƒìœ„ íƒœê·¸(li)ì—ì„œ writing í´ë˜ìŠ¤ë¥¼ ì°¾ìŒ
                press = "ì‚¬ì„¤"
                parent_li = a.find_parent('li')
                if parent_li:
                    press_span = parent_li.find('span', class_='writing')
                    if press_span:
                        press = press_span.get_text(strip=True)
                
                # 5. ì œëª© ì •ë¦¬
                if title.startswith(press):
                    title = title[len(press):].lstrip('[] ')
                
                news_data.append({'title': title, 'link': link, 'press': press})
                seen_links.add(link)
                found_count += 1
                
            except: continue
            
        print(f" -> {found_count}ê°œ ë°œê²¬")
        time.sleep(0.5)

    if news_data:
        # íŒŒì¼ ì €ì¥
        with open("index.html", "w", encoding="utf-8") as f:
            f.write(create_html(news_data))
        
        # í…”ë ˆê·¸ë¨ ì „ì†¡ (ìµœëŒ€ 3500ìì”© ëŠì–´ì„œ ì „ì†¡)
        msg_header = f"ğŸ“° ìˆ˜ì§‘ ì„±ê³µ! ì´ {len(news_data)}ê°œ\n\n"
        current_msg = msg_header
        
        for news in news_data:
            line = f"[{news['press']}] {news['title']}\n{news['link']}\n\n"
            if len(current_msg) + len(line) > 3500:
                send_msg(current_msg)
                current_msg = ""
            current_msg += line
            
        current_msg += f"ğŸ‘‰ https://chojh16.github.io/daily-editorial/"
        send_msg(current_msg)
        
    else:
        # [ë””ë²„ê¹…ìš©] ë§Œì•½ ì´ë²ˆì—ë„ ì‹¤íŒ¨í•˜ë©´ ë„¤ì´ë²„ê°€ ë­˜ ë³´ì—¬ì¤¬ëŠ”ì§€ ê¸€ììˆ˜ë¼ë„ ì°ì–´ë´„
        debug_info = f"âŒ ì‹¤íŒ¨.. (í˜ì´ì§€ ì‘ë‹µ ê¸¸ì´: {len(res.text)}ì)"
        send_msg(debug_info)

except Exception as e:
    send_msg(f"ğŸ”¥ ì—ëŸ¬ ë°œìƒ: {e}")
    exit(1)
