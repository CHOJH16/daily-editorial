name: Daily Editorial Scraper

on:
  schedule:
    # UTC 20:30 = 한국 시간 오전 05:30
    # (일~금 실행 = 한국 월~토 실행)
    - cron: '30 20 * * 0-5'
  workflow_dispatch:

permissions:
  contents: write

jobs:
  build:
    runs-on: ubuntu-latest
    # [추가됨] 최대 60분까지만 실행 허용 (30분 대기 시간 고려하여 넉넉하게 설정)
    # 만약 1시간이 넘도록 안 끝나면 강제로 끕니다 (무료 시간 낭비 방지)
    timeout-minutes: 60
    
    steps:
    - name: 저장소 체크아웃
      uses: actions/checkout@v3

    - name: 파이썬 설정
      uses: actions/setup-python@v4
      with:
        python-version: '3.9'

    - name: 필요한 도구 설치
      run: |
        pip install requests beautifulsoup4

    - name: 크롤러 실행
      env:
        TELEGRAM_TOKEN: ${{ secrets.TELEGRAM_TOKEN }}
        CHAT_ID: ${{ secrets.CHAT_ID }}
      run: |
        python scraper.py

    - name: 결과물 저장 (Commit & Push)
      run: |
        git config --global user.name 'Daily News Bot'
        git config --global user.email 'bot@noreply.github.com'
        git add index.html
        git diff --quiet && git diff --staged --quiet || (git commit -m "Update editorials" && git push)
